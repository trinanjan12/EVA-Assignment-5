{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ovrup/EVA-Assignment-5/blob/master/EVA_Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7AeWMDhuSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSjrr3Izh3pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all necessary modules in Keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRRChybch31I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1c2fe600-f2ad-429c-a4b0-132322020ab4"
      },
      "source": [
        "\n",
        "# example of standardizing a image dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, test_Y) = mnist.load_data()\n",
        "print(f'training set = {trainX.shape}')\n",
        "print(f'test set = {testX.shape}')\n",
        "\n",
        "# reshape dataset to have a single channel\n",
        "# The train & test set are 3D matrix.The training set is of shape (60000,28,28) & test set is (10000,28,28). But here the CNN model expects\n",
        "# the input shape to be 4D i.e (no of samples,height,width,channel).Channel implies whether the image is gray scale or colour(RGB). In case of\n",
        "# RGB image the 4th dimension would be 3. In this case the images are gray scale. Hence, it is 1. That's why training & test set are reshaped into\n",
        "# matrices of shape (60000,28,28,1) & (10000,28,28,1) respectively.\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "print(f'Reshaped training set = {trainX.shape}')\n",
        "print(f'Reshaped test set = {testX.shape}')\n",
        "\n",
        "# report pixel max, min, means and standard deviations\n",
        "print('training maximum pixel = %.3f , minimum pixel = %.3f' %(trainX.max(), trainX.min()))\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
        "\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std(), batchX.max(), batchX.min())\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set = (60000, 28, 28)\n",
            "test set = (10000, 28, 28)\n",
            "Reshaped training set = (60000, 28, 28, 1)\n",
            "Reshaped test set = (10000, 28, 28, 1)\n",
            "training maximum pixel = 255.000 , minimum pixel = 0.000\n",
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator mean=33.318, std=78.567\n",
            "(64, 28, 28, 1) 0.038626786 1.0434185 2.8215446 -0.42407447\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_GaFwXh4K8",
        "colab_type": "code",
        "outputId": "7cf0d410-1ce6-4f5e-dca1-b2d98df8a9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 1st 10 labels for training set. As printed below the 1st element is 5 which implies the 1st image of training set is of digit 5 and so on. \n",
        "trainY[:10]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4HAeMk-h4Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# As shown above the label matrix(Y_train & Y_test) holds values that implies what digit the image is about. So, keras may find some relational order\n",
        "# between these values. To avoid this problem we hot encode the matrix into a binary matrix. This matrix has number of columns equal to the number\n",
        "# of classes(10 columns in this scenario). Each row defines the label of one sample point in data set & has only one '1' & others are '0'. '1' at\n",
        "# particular index position implies the digit equal to the column number. For example, the 1st row(1st sample of training data set) has '1' at column\n",
        "# number 5(starting from 0) which means this is image of digit 5.\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices \n",
        "trainY = np_utils.to_categorical(trainY, 10)\n",
        "testY = np_utils.to_categorical(test_Y, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnEjyfkyh4RJ",
        "colab_type": "code",
        "outputId": "c2c3e468-ab75-4280-bff0-8e889b794dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Label matrix hot encoded into binary matrix\n",
        "trainY[:10]"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy_ibvgrX4Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input = 28*28*1\n",
        "model.add(Convolution2D(10, kernel_size = (3,3), input_shape = (28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# Input = 26*26*10\n",
        "model.add(Convolution2D(16, kernel_size = (3,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# Input = 24*24*16\n",
        "model.add(Convolution2D(16, kernel_size = (3,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# Input = 22*22*16\n",
        "model.add(Convolution2D(10, kernel_size=(1,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# Input = 22*22*10\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# Input = 11*11*10\n",
        "model.add(Convolution2D(16, kernel_size=(3,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "# Input = 9*9*16\n",
        "model.add(Convolution2D(16, kernel_size=(3,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# Input = 7*7*16\n",
        "model.add(Convolution2D(10, kernel_size=(1,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# Input = 7*7*10\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "# Input = 1*1*10\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGYZKoyiUct",
        "colab_type": "code",
        "outputId": "1ee0fd58-ce78-4e5e-eb69-16c1091bdb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "source": [
        "# summary() function displays the model structure i.e for each layer how many parameters used, what is the shape of output image\n",
        "model.summary()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 22, 22, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,278\n",
            "Trainable params: 13,090\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WivZHFD6qz8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKkc6pAmiUmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with SGD optimizer. Since this is multi class problem (10 classes) 'categorical_crossentropy' is used as loss function.\n",
        "# accuracy is used as metrics which means while training this accuracy metrics will be monitored.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=SGD(lr=0.1,decay = 0.00001, momentum = 0.8),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeE58zvhi1OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKlIFN4uwPiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9874c588-f76d-43e0-b5e2-6f0b6874f3c4"
      },
      "source": [
        "# Creates batches of training data yielded from generator\n",
        "train_iterator = datagen.flow(trainX, trainY,batch_size = 64)\n",
        "print(len(train_iterator))\n",
        "\n",
        "# Creates batches of test data yielded from generator\n",
        "test_iterator = datagen.flow(testX, testY,batch_size = 64)\n",
        "print(len(test_iterator))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938\n",
            "157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZcCcCL3iUte",
        "colab_type": "code",
        "outputId": "02442917-73d1-4ef9-f0bb-ab83cfdc2bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        }
      },
      "source": [
        "# Train the model with fit() which takes the training data set along with the label matrix. Epoch means one round of the whole data set. Batch size\n",
        "# determines in an epoch how many images to be processed parallelly. Batch size 32 means in an epoch in one iteration 32 images are processed.\n",
        "model.fit_generator(train_iterator, steps_per_epoch =len(train_iterator) , epochs=40, callbacks = callbacks_list,validation_data = test_iterator, validation_steps = len(test_iterator) , verbose = 1)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0701 - acc: 0.9787 - val_loss: 0.0386 - val_acc: 0.9875\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.98750, saving model to weights.best.hdf5\n",
            "Epoch 2/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0434 - acc: 0.9862 - val_loss: 0.0383 - val_acc: 0.9885\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.98750 to 0.98850, saving model to weights.best.hdf5\n",
            "Epoch 3/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0384 - acc: 0.9878 - val_loss: 0.0334 - val_acc: 0.9883\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.98850\n",
            "Epoch 4/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0356 - acc: 0.9887 - val_loss: 0.0352 - val_acc: 0.9888\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.98850 to 0.98880, saving model to weights.best.hdf5\n",
            "Epoch 5/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.0252 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98880 to 0.99150, saving model to weights.best.hdf5\n",
            "Epoch 6/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0316 - acc: 0.9899 - val_loss: 0.0203 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.99150 to 0.99290, saving model to weights.best.hdf5\n",
            "Epoch 7/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0294 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.99290\n",
            "Epoch 8/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0286 - acc: 0.9908 - val_loss: 0.0195 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99290 to 0.99350, saving model to weights.best.hdf5\n",
            "Epoch 9/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0263 - acc: 0.9915 - val_loss: 0.0211 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99350\n",
            "Epoch 10/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0248 - acc: 0.9918 - val_loss: 0.0236 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99350\n",
            "Epoch 11/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0242 - acc: 0.9921 - val_loss: 0.0262 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99350\n",
            "Epoch 12/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0258 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99350\n",
            "Epoch 13/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0195 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.99350 to 0.99360, saving model to weights.best.hdf5\n",
            "Epoch 14/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0233 - acc: 0.9921 - val_loss: 0.0219 - val_acc: 0.9925\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.99360\n",
            "Epoch 15/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0225 - acc: 0.9925 - val_loss: 0.0219 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.99360\n",
            "Epoch 16/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0202 - acc: 0.9932 - val_loss: 0.0290 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99360\n",
            "Epoch 17/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0252 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99360\n",
            "Epoch 18/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0200 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.99360 to 0.99420, saving model to weights.best.hdf5\n",
            "Epoch 19/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0194 - acc: 0.9936 - val_loss: 0.0256 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.99420\n",
            "Epoch 20/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0330 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99420\n",
            "Epoch 21/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0203 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99420\n",
            "Epoch 22/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0214 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99420\n",
            "Epoch 23/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0180 - acc: 0.9943 - val_loss: 0.0283 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99420\n",
            "Epoch 24/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0227 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99420\n",
            "Epoch 25/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0230 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99420\n",
            "Epoch 26/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0182 - val_acc: 0.9947\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.99420 to 0.99470, saving model to weights.best.hdf5\n",
            "Epoch 27/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0226 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99470\n",
            "Epoch 28/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0207 - val_acc: 0.9938\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99470\n",
            "Epoch 29/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0158 - acc: 0.9946 - val_loss: 0.0233 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99470\n",
            "Epoch 30/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0163 - acc: 0.9945 - val_loss: 0.0235 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99470\n",
            "Epoch 31/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0250 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99470\n",
            "Epoch 32/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0238 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99470\n",
            "Epoch 33/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0205 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99470\n",
            "Epoch 34/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0233 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99470\n",
            "Epoch 35/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0210 - val_acc: 0.9941\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99470\n",
            "Epoch 36/40\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0247 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99470\n",
            "Epoch 37/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0213 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99470\n",
            "Epoch 38/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0139 - acc: 0.9952 - val_loss: 0.0240 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99470\n",
            "Epoch 39/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.0216 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99470\n",
            "Epoch 40/40\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0226 - val_acc: 0.9932\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d80f4a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvcVXIlrkHD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights\n",
        "model.load_weights(\"weights.best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lUiqnzdkIhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with SGD optimizer. Since this is multi class problem (10 classes) 'categorical_crossentropy' is used as loss function.\n",
        "# accuracy is used as metrics which means while training this accuracy metrics will be monitored.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=SGD(lr=0.01,decay = 0.00001, momentum = 0.8),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuMcqXEokNDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "179006dd-cad9-4dd4-fb5c-8a2db45668fd"
      },
      "source": [
        "# Now the model is trained which means the weights are optimized. model.evaluate() predicts the classes of each image in test set & then calculate\n",
        "# test set loss & accuracy.\n",
        "score = model.evaluate_generator(test_iterator, steps = len(test_iterator), verbose=1)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 13ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z31gnRtukaG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2f5de12-8a35-420e-f9c3-9173875da4a1"
      },
      "source": [
        "# score is a vector that holds the test set loss & accuracy\n",
        "print(score)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.016879419930209406, 0.995]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpYzj-yaka7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the class of each image in test set & stores in y_pred matrix\n",
        "y_pred = model.predict_classes(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1dVrFA5ynJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaped the test set to (10000, 28, 28) to be able to display images\n",
        "testX = testX.reshape(testX.shape[0], width, height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfDLnyqg7uQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5a3ba7d-5067-4130-8dfd-bd42a975b8fa"
      },
      "source": [
        "# Shape of test set\n",
        "print(testX.shape)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5tTsReFiik-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing the indexes of miss classified images in a list\n",
        "miss_classified = [idx for idx, i in enumerate(y_pred) if i != test_Y[idx]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2EpjIY599kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All miss classified images are taken from test set & stored in a new numpy array\n",
        "miss_classified_images = np.array([testX[i] for i in miss_classified])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaJ_nYUzCzFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "99a6abe7-d588-4b08-de0d-6234d934aefc"
      },
      "source": [
        "# Displaying 25 miss classified images\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(figsize=(10, 10))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "for i in range(25):\n",
        "    ax = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(miss_classified_images[i])\n",
        "    # label the image with the target value\n",
        "    ax.text(0, 7, str(y_pred[i]))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAALlCAYAAABjOpj+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGbYmvH7l4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}